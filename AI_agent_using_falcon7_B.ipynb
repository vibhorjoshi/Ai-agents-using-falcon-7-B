{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install langchain transformers torch beautifulsoup4 requests accelerate\n",
        "!pip install langchain_community\n",
        "# Import required modules\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "\n",
        "# Load Falcon-7B Model from Hugging Face\n",
        "model_name = \"tiiuae/falcon-7b-instruct\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.float16)\n",
        "\n",
        "# Create the text generation pipeline\n",
        "summarizer = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
        "\n",
        "# Wrap the model for LangChain\n",
        "llm = HuggingFacePipeline(pipeline=summarizer)\n",
        "\n",
        "# Function to scrape website content\n",
        "def scrape_website(url):\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        text = ' '.join([p.text for p in soup.find_all('p')])  # Extract text from <p> tags\n",
        "        return text\n",
        "    else:\n",
        "        return f\"‚ùå Failed to fetch website. Status code: {response.status_code}\"\n",
        "\n",
        "# Function to analyze and summarize scraped content\n",
        "def analyze_content(url):\n",
        "    scraped_text = scrape_website(url)\n",
        "\n",
        "    if \"Failed\" in scraped_text:\n",
        "        return scraped_text  # Return error message if scraping failed\n",
        "\n",
        "    # Limit text length to 1024 tokens (model constraint)\n",
        "    input_text = scraped_text[:1024]\n",
        "\n",
        "    # Generate summary using Falcon-7B\n",
        "    summary = llm(f\"Summarize the following text:\\n{input_text}\")\n",
        "    return summary\n",
        "\n",
        "# User Input for URL\n",
        "url = input(\"üîó Enter the URL to scrape: \")\n",
        "summary = analyze_content(url)\n",
        "\n",
        "# Print Summary\n",
        "print(\"\\nüìÑ Webpage Summary:\\n\", summary)"
      ],
      "metadata": {
        "id": "Z0P9IufDH9U2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install streamlit langchain transformers torch beautifulsoup4 requests accelerate\n",
        "\n",
        "import streamlit as st\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "# Load Falcon-7B Model from Hugging Face\n",
        "model_name = \"tiiuae/falcon-7b-instruct\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.float16)\n",
        "\n",
        "# Create the text generation pipeline\n",
        "summarizer = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
        "\n",
        "# Wrap the model for LangChain\n",
        "llm = HuggingFacePipeline(pipeline=summarizer)\n",
        "\n",
        "# Function to scrape website content\n",
        "def scrape_website(url):\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        text = ' '.join([p.text for p in soup.find_all('p')])  # Extract text from <p> tags\n",
        "        return text\n",
        "    else:\n",
        "        return f\"‚ùå Failed to fetch website. Status code: {response.status_code}\"\n",
        "\n",
        "# Function to analyze and summarize scraped content\n",
        "def analyze_content(url):\n",
        "    scraped_text = scrape_website(url)\n",
        "\n",
        "    if \"Failed\" in scraped_text:\n",
        "        return scraped_text  # Return error message if scraping failed\n",
        "\n",
        "    # Limit text length to 1024 tokens (model constraint)\n",
        "    input_text = scraped_text[:1024]\n",
        "\n",
        "    # Generate summary using Falcon-7B\n",
        "    summary = llm(f\"Summarize the following text:\\n{input_text}\")\n",
        "    return summary\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"üåê Web Scraper & Summarizer using Falcon-7B\")\n",
        "st.write(\"Enter a URL, and this app will scrape and summarize its content.\")\n",
        "\n",
        "url = st.text_input(\"üîó Enter the URL:\")\n",
        "if st.button(\"Summarize\"):\n",
        "    if url:\n",
        "        summary = analyze_content(url)\n",
        "        st.subheader(\"üìÑ Webpage Summary:\")\n",
        "        st.write(summary)\n",
        "    else:\n",
        "        st.error(\"‚ùó Please enter a valid URL.\")"
      ],
      "metadata": {
        "id": "QTyvkv5HInvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the new GitHub token securely\n",
        "GITHUB_TOKEN = \"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\"\n",
        "\n",
        "# Set up Git remote URL with authentication\n",
        "!git remote set-url origin https://{GITHUB_TOKEN}@github.com/vibhorjoshi/Ai-agents-using-falcon-7-B.git\n",
        "\n",
        "# Push changes to GitHub\n",
        "!git push origin main"
      ],
      "metadata": {
        "id": "Gtxgk8o8OTA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-ZTp12eFIoMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Git in Colab\n",
        "!git config --global user.name \"vibhorjoshi\"\n",
        "!git config --global user.email \"vibhorjoshi40@gmail.com\"\n",
        "\n",
        "# Clone your GitHub repo (Replace 'your-repo' with your actual repo)\n",
        "!git clone https://github.com/vibhorjoshi/Ai-agents-using-falcon-7-B\n",
        "%cd Ai-agents-using-falcon-7-B\n",
        "\n",
        "# Save the Streamlit file\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "import streamlit as st\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "# Load Falcon-7B Model from Hugging Face\n",
        "model_name = \"tiiuae/falcon-7b-instruct\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.float16)\n",
        "\n",
        "# Create the text generation pipeline\n",
        "summarizer = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
        "\n",
        "# Wrap the model for LangChain\n",
        "llm = HuggingFacePipeline(pipeline=summarizer)\n",
        "\n",
        "# Function to scrape website content\n",
        "def scrape_website(url):\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        text = ' '.join([p.text for p in soup.find_all('p')])  # Extract text from <p> tags\n",
        "        return text\n",
        "    else:\n",
        "        return f\"‚ùå Failed to fetch website. Status code: {response.status_code}\"\n",
        "\n",
        "# Function to analyze and summarize scraped content\n",
        "def analyze_content(url):\n",
        "    scraped_text = scrape_website(url)\n",
        "\n",
        "    if \"Failed\" in scraped_text:\n",
        "        return scraped_text  # Return error message if scraping failed\n",
        "\n",
        "    # Limit text length to 1024 tokens (model constraint)\n",
        "    input_text = scraped_text[:1024]\n",
        "\n",
        "    # Generate summary using Falcon-7B\n",
        "    summary = llm(f\"Summarize the following text:\\n{input_text}\")\n",
        "    return summary\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"üåê Web Scraper & Summarizer using Falcon-7B\")\n",
        "st.write(\"Enter a URL, and this app will scrape and summarize its content.\")\n",
        "\n",
        "url = st.text_input(\"üîó Enter the URL:\")\n",
        "if st.button(\"Summarize\"):\n",
        "    if url:\n",
        "        summary = analyze_content(url)\n",
        "        st.subheader(\"üìÑ Webpage Summary:\")\n",
        "        st.write(summary)\n",
        "    else:\n",
        "        st.error(\"‚ùó Please enter a valid URL.\")\n",
        "    # Paste the Streamlit code from above here\n",
        "    \"\"\")\n",
        "\n",
        "# Add & commit changes\n",
        "!git add app.py\n",
        "!git commit -m \"Added Streamlit Web Scraper with Falcon-7B\"\n",
        "\n",
        "# Push to GitHub\n",
        "!git push origin main"
      ],
      "metadata": {
        "id": "V40p0QFzMKSA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}